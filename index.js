const express = require("express");
const cors = require("cors");
const bodyParser = require("body-parser");
const { OpenAI } = require("openai");
require("dotenv").config(); // Ï†ÏŒÏÏ„Ï‰ÏƒÎ· .env Î¼ÎµÏ„Î±Î²Î»Î·Ï„ÏÎ½

const app = express(); // <== Î‘Ï…Ï„ÏŒ Î­Î»ÎµÎ¹Ï€Îµ
const port = process.env.PORT || 3000;

app.use(cors());
app.use(bodyParser.json());

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

app.post("/chat", async (req, res) => {
  const prompt = req.body.prompt;

  if (!prompt) {
    return res.status(400).json({ error: "No prompt provided" });
  }

  try {
    const completion = await openai.chat.completions.create({
      model: "gpt-3.5-turbo",
      messages: [{ role: "user", content: prompt }],
    });

    res.json({ reply: completion.choices[0].message.content });
  } catch (error) {
    console.error("AI Error:", error);
    res.status(500).json({ reply: "âš ï¸ Error generating response." });
  }
});

app.get("/", (req, res) => {
  res.send("âœ… NEXIS GPT-Backend is running.");
});

app.listen(port, () => {
  console.log(`ğŸš€ Server running on port ${port}`);
});
